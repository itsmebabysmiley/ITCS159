{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dogs ,Canis lupus familiaris, are domesticated mammals,\\nnot natural wild animals.', 'They were originally bred from\\nwolves.', 'They have been bred by humans for a long time, and\\nwere the first animals ever to be domesticated.', 'Today, some dogs are used as pets, others are used to help\\nhumans do their work.', 'They are a popular pet because they\\nare usually playful, friendly, loyal and listen to humans.', 'Thirty million dogs in the United States are registered as\\npets.', 'Dogs eat both meat and vegetables, often mixed\\ntogether and sold in stores as dog food.', 'Dogs often have\\njobs, including as police dogs, army dogs, assistance dogs,\\nfire dogs, messenger dogs, hunting dogs, herding dogs, or\\nrescue dogs.', 'They are sometimes called \"canines\" from the Latin word for dog\\n- canis.', 'Sometimes people also use \"dog\" to describe other\\ncanids, such as wolves.', 'A baby dog is called a pup or puppy.', 'A dog is called a puppy until it is about one year old.', 'Dogs are sometimes referred to as \"man’s best friend\" because\\nthey are kept as domestic pets and are usually loyal and\\nlike being around humans.']\n"
     ]
    }
   ],
   "source": [
    "text=\"\"\"Dogs ,Canis lupus familiaris, are domesticated mammals,\n",
    "not natural wild animals. They were originally bred from\n",
    "wolves. They have been bred by humans for a long time, and\n",
    "were the first animals ever to be domesticated.\n",
    "Today, some dogs are used as pets, others are used to help\n",
    "humans do their work. They are a popular pet because they\n",
    "are usually playful, friendly, loyal and listen to humans.\n",
    "Thirty million dogs in the United States are registered as\n",
    "pets. Dogs eat both meat and vegetables, often mixed\n",
    "together and sold in stores as dog food. Dogs often have\n",
    "jobs, including as police dogs, army dogs, assistance dogs,\n",
    "fire dogs, messenger dogs, hunting dogs, herding dogs, or\n",
    "rescue dogs.\n",
    "They are sometimes called \"canines\" from the Latin word for dog\n",
    "- canis. Sometimes people also use \"dog\" to describe other\n",
    "canids, such as wolves. A baby dog is called a pup or puppy.\n",
    "A dog is called a puppy until it is about one year old.\n",
    "Dogs are sometimes referred to as \"man’s best friend\" because\n",
    "they are kept as domestic pets and are usually loyal and\n",
    "like being around humans.\"\"\"\n",
    "tokenized_text=sent_tokenize(text)\n",
    "print(tokenized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# How many sentences in the paragraph?\n",
    "print(len(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They have been bred by humans for a long time, and\n",
      "were the first animals ever to be domesticated.\n"
     ]
    }
   ],
   "source": [
    "# What is the third sentences in the paragraph?\n",
    "print(tokenized_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'a', 'long', 'time', ',', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', ',', 'some', 'dogs', 'are', 'used', 'as', 'pets', ',', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'a', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', ',', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', ',', 'including', 'as', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', ',', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'is', 'called', 'a', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'is', 'called', 'a', 'puppy', 'until', 'it', 'is', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_word=word_tokenize(text)\n",
    "print(tokenized_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"''\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " 'A',\n",
       " 'Canis',\n",
       " 'Dogs',\n",
       " 'Latin',\n",
       " 'Sometimes',\n",
       " 'States',\n",
       " 'They',\n",
       " 'Thirty',\n",
       " 'Today',\n",
       " 'United',\n",
       " '``',\n",
       " 'a',\n",
       " 'about',\n",
       " 'also',\n",
       " 'and',\n",
       " 'animals',\n",
       " 'are',\n",
       " 'army',\n",
       " 'around',\n",
       " 'as',\n",
       " 'assistance',\n",
       " 'baby',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'being',\n",
       " 'best',\n",
       " 'both',\n",
       " 'bred',\n",
       " 'by',\n",
       " 'called',\n",
       " 'canids',\n",
       " 'canines',\n",
       " 'canis',\n",
       " 'describe',\n",
       " 'do',\n",
       " 'dog',\n",
       " 'dogs',\n",
       " 'domestic',\n",
       " 'domesticated',\n",
       " 'eat',\n",
       " 'ever',\n",
       " 'familiaris',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'food',\n",
       " 'for',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'from',\n",
       " 'have',\n",
       " 'help',\n",
       " 'herding',\n",
       " 'humans',\n",
       " 'hunting',\n",
       " 'in',\n",
       " 'including',\n",
       " 'is',\n",
       " 'it',\n",
       " 'jobs',\n",
       " 'kept',\n",
       " 'like',\n",
       " 'listen',\n",
       " 'long',\n",
       " 'loyal',\n",
       " 'lupus',\n",
       " 'mammals',\n",
       " 'man',\n",
       " 'meat',\n",
       " 'messenger',\n",
       " 'million',\n",
       " 'mixed',\n",
       " 'natural',\n",
       " 'not',\n",
       " 'often',\n",
       " 'old',\n",
       " 'one',\n",
       " 'or',\n",
       " 'originally',\n",
       " 'other',\n",
       " 'others',\n",
       " 'people',\n",
       " 'pet',\n",
       " 'pets',\n",
       " 'playful',\n",
       " 'police',\n",
       " 'popular',\n",
       " 'pup',\n",
       " 'puppy',\n",
       " 'referred',\n",
       " 'registered',\n",
       " 'rescue',\n",
       " 's',\n",
       " 'sold',\n",
       " 'some',\n",
       " 'sometimes',\n",
       " 'stores',\n",
       " 'such',\n",
       " 'the',\n",
       " 'their',\n",
       " 'they',\n",
       " 'time',\n",
       " 'to',\n",
       " 'together',\n",
       " 'until',\n",
       " 'use',\n",
       " 'used',\n",
       " 'usually',\n",
       " 'vegetables',\n",
       " 'were',\n",
       " 'wild',\n",
       " 'wolves',\n",
       " 'word',\n",
       " 'work',\n",
       " 'year',\n",
       " '’']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(tokenized_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenized_word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Dogs': 4,\n",
       "         'Canis': 1,\n",
       "         'lupus': 1,\n",
       "         'familiaris': 1,\n",
       "         'are': 10,\n",
       "         'domesticated': 2,\n",
       "         'mammals': 1,\n",
       "         'not': 1,\n",
       "         'natural': 1,\n",
       "         'wild': 1,\n",
       "         'animals': 2,\n",
       "         'They': 4,\n",
       "         'were': 2,\n",
       "         'originally': 1,\n",
       "         'bred': 2,\n",
       "         'from': 2,\n",
       "         'wolves': 2,\n",
       "         'have': 2,\n",
       "         'been': 1,\n",
       "         'by': 1,\n",
       "         'humans': 4,\n",
       "         'for': 2,\n",
       "         'a': 4,\n",
       "         'long': 1,\n",
       "         'time': 1,\n",
       "         'and': 6,\n",
       "         'the': 3,\n",
       "         'first': 1,\n",
       "         'ever': 1,\n",
       "         'to': 5,\n",
       "         'be': 1,\n",
       "         'Today': 1,\n",
       "         'some': 1,\n",
       "         'dogs': 10,\n",
       "         'used': 2,\n",
       "         'as': 7,\n",
       "         'pets': 3,\n",
       "         'others': 1,\n",
       "         'help': 1,\n",
       "         'do': 1,\n",
       "         'their': 1,\n",
       "         'work': 1,\n",
       "         'popular': 1,\n",
       "         'pet': 1,\n",
       "         'because': 2,\n",
       "         'they': 2,\n",
       "         'usually': 2,\n",
       "         'playful': 1,\n",
       "         'friendly': 1,\n",
       "         'loyal': 2,\n",
       "         'listen': 1,\n",
       "         'Thirty': 1,\n",
       "         'million': 1,\n",
       "         'in': 2,\n",
       "         'United': 1,\n",
       "         'States': 1,\n",
       "         'registered': 1,\n",
       "         'eat': 1,\n",
       "         'both': 1,\n",
       "         'meat': 1,\n",
       "         'vegetables': 1,\n",
       "         'often': 2,\n",
       "         'mixed': 1,\n",
       "         'together': 1,\n",
       "         'sold': 1,\n",
       "         'stores': 1,\n",
       "         'dog': 5,\n",
       "         'food': 1,\n",
       "         'jobs': 1,\n",
       "         'including': 1,\n",
       "         'police': 1,\n",
       "         'army': 1,\n",
       "         'assistance': 1,\n",
       "         'fire': 1,\n",
       "         'messenger': 1,\n",
       "         'hunting': 1,\n",
       "         'herding': 1,\n",
       "         'or': 2,\n",
       "         'rescue': 1,\n",
       "         'sometimes': 2,\n",
       "         'called': 3,\n",
       "         'canines': 1,\n",
       "         'Latin': 1,\n",
       "         'word': 1,\n",
       "         'canis': 1,\n",
       "         'Sometimes': 1,\n",
       "         'people': 1,\n",
       "         'also': 1,\n",
       "         'use': 1,\n",
       "         'describe': 1,\n",
       "         'other': 1,\n",
       "         'canids': 1,\n",
       "         'such': 1,\n",
       "         'A': 2,\n",
       "         'baby': 1,\n",
       "         'is': 3,\n",
       "         'pup': 1,\n",
       "         'puppy': 2,\n",
       "         'until': 1,\n",
       "         'it': 1,\n",
       "         'about': 1,\n",
       "         'one': 1,\n",
       "         'year': 1,\n",
       "         'old': 1,\n",
       "         'referred': 1,\n",
       "         'man': 1,\n",
       "         's': 1,\n",
       "         'best': 1,\n",
       "         'friend': 1,\n",
       "         'kept': 1,\n",
       "         'domestic': 1,\n",
       "         'like': 1,\n",
       "         'being': 1,\n",
       "         'around': 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "letter = re.compile('.*[A-Za-z0-9].*')  # must contain a letter or digit\n",
    "dic = [w for w in tokenized_word if letter.match(w)]\n",
    "counts = Counter(dic)\n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = counts.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n"
     ]
    }
   ],
   "source": [
    "# How many words in the paragraph?\n",
    "print(sum(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many words in the first sentence?\n",
    "tokenized_word2=word_tokenize(tokenized_text[0])\n",
    "print(tokenized_word2)\n",
    "count = 0\n",
    "for i in tokenized_word2:\n",
    "    if not (i == ',' or i == '.'):\n",
    "        count += 1\n",
    "count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " '.',\n",
       " 'Canis',\n",
       " 'Dogs',\n",
       " 'animals',\n",
       " 'are',\n",
       " 'domesticated',\n",
       " 'familiaris',\n",
       " 'lupus',\n",
       " 'mammals',\n",
       " 'natural',\n",
       " 'not',\n",
       " 'wild']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(tokenized_word2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words in the last sentence?\n",
    "# 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 120 samples and 229 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# Do you find repeat words?\n",
    "fdist1 = FreqDist(tokenized_word)\n",
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18),\n",
       " ('.', 13),\n",
       " ('are', 10),\n",
       " ('dogs', 10),\n",
       " ('as', 7),\n",
       " ('and', 6),\n",
       " ('to', 5),\n",
       " ('dog', 5),\n",
       " ('Dogs', 4),\n",
       " ('They', 4),\n",
       " ('humans', 4),\n",
       " ('a', 4),\n",
       " ('the', 3),\n",
       " ('pets', 3),\n",
       " ('called', 3),\n",
       " ('``', 3),\n",
       " (\"''\", 3),\n",
       " ('is', 3),\n",
       " ('domesticated', 2),\n",
       " ('animals', 2),\n",
       " ('were', 2),\n",
       " ('bred', 2),\n",
       " ('from', 2),\n",
       " ('wolves', 2),\n",
       " ('have', 2),\n",
       " ('for', 2),\n",
       " ('used', 2),\n",
       " ('because', 2),\n",
       " ('they', 2),\n",
       " ('usually', 2),\n",
       " ('loyal', 2),\n",
       " ('in', 2),\n",
       " ('often', 2),\n",
       " ('or', 2),\n",
       " ('sometimes', 2),\n",
       " ('A', 2),\n",
       " ('puppy', 2),\n",
       " ('Canis', 1),\n",
       " ('lupus', 1),\n",
       " ('familiaris', 1),\n",
       " ('mammals', 1),\n",
       " ('not', 1),\n",
       " ('natural', 1),\n",
       " ('wild', 1),\n",
       " ('originally', 1),\n",
       " ('been', 1),\n",
       " ('by', 1),\n",
       " ('long', 1),\n",
       " ('time', 1),\n",
       " ('first', 1),\n",
       " ('ever', 1),\n",
       " ('be', 1),\n",
       " ('Today', 1),\n",
       " ('some', 1),\n",
       " ('others', 1),\n",
       " ('help', 1),\n",
       " ('do', 1),\n",
       " ('their', 1),\n",
       " ('work', 1),\n",
       " ('popular', 1),\n",
       " ('pet', 1),\n",
       " ('playful', 1),\n",
       " ('friendly', 1),\n",
       " ('listen', 1),\n",
       " ('Thirty', 1),\n",
       " ('million', 1),\n",
       " ('United', 1),\n",
       " ('States', 1),\n",
       " ('registered', 1),\n",
       " ('eat', 1),\n",
       " ('both', 1),\n",
       " ('meat', 1),\n",
       " ('vegetables', 1),\n",
       " ('mixed', 1),\n",
       " ('together', 1),\n",
       " ('sold', 1),\n",
       " ('stores', 1),\n",
       " ('food', 1),\n",
       " ('jobs', 1),\n",
       " ('including', 1),\n",
       " ('police', 1),\n",
       " ('army', 1),\n",
       " ('assistance', 1),\n",
       " ('fire', 1),\n",
       " ('messenger', 1),\n",
       " ('hunting', 1),\n",
       " ('herding', 1),\n",
       " ('rescue', 1),\n",
       " ('canines', 1),\n",
       " ('Latin', 1),\n",
       " ('word', 1),\n",
       " ('-', 1),\n",
       " ('canis', 1),\n",
       " ('Sometimes', 1),\n",
       " ('people', 1),\n",
       " ('also', 1),\n",
       " ('use', 1),\n",
       " ('describe', 1),\n",
       " ('other', 1),\n",
       " ('canids', 1),\n",
       " ('such', 1),\n",
       " ('baby', 1),\n",
       " ('pup', 1),\n",
       " ('until', 1),\n",
       " ('it', 1),\n",
       " ('about', 1),\n",
       " ('one', 1),\n",
       " ('year', 1),\n",
       " ('old', 1),\n",
       " ('referred', 1),\n",
       " ('man', 1),\n",
       " ('’', 1),\n",
       " ('s', 1),\n",
       " ('best', 1),\n",
       " ('friend', 1),\n",
       " ('kept', 1),\n",
       " ('domestic', 1),\n",
       " ('like', 1),\n",
       " ('being', 1),\n",
       " ('around', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 120 samples and 229 outcomes>\n"
     ]
    }
   ],
   "source": [
    "fdist = FreqDist(tokenized_word)\n",
    "print(fdist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 18, '.': 13, 'are': 10, 'dogs': 10, 'as': 7, 'and': 6, 'to': 5, 'dog': 5, 'Dogs': 4, 'They': 4, ...})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 18),\n",
       " ('.', 13),\n",
       " ('are', 10),\n",
       " ('dogs', 10),\n",
       " ('as', 7),\n",
       " ('and', 6),\n",
       " ('to', 5),\n",
       " ('dog', 5),\n",
       " ('Dogs', 4),\n",
       " ('They', 4)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the top ten most common word?\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = [\"is\", \"a\", \"this\", \",\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in', 'ma', 't', 'how', 'mightn', 'further', 'between', \"couldn't\", \"you'd\", 'did', 'i', 'most', 'm', 'here', 'up', 'herself', 'your', 'where', 'our', 'yourselves', 'this', 'you', \"won't\", 'out', 'until', 'other', 'his', 'an', \"doesn't\", 'then', 'and', 'own', 're', 'than', \"aren't\", 'doesn', 'if', 'after', 'these', 'it', 'any', 'weren', 'at', 'more', \"don't\", 'whom', 'all', 'am', 'shouldn', 'her', 'themselves', 'because', 'd', 'for', 'again', 'very', 'o', 'him', 'that', 'is', 'himself', 'being', 'isn', \"needn't\", 'were', 'didn', \"it's\", 'few', 'them', 'above', 'we', 'off', 'yours', 'theirs', 'hadn', 'only', 'the', \"you've\", 'll', 'does', 'before', 'will', 'who', \"didn't\", \"hadn't\", 'can', \"should've\", 'myself', 'so', 'some', 'couldn', 'when', 'needn', \"wasn't\", 'ain', 'been', 'their', 'a', 'hasn', 'are', \"shan't\", 'why', 'have', 'there', 'itself', 'but', 'down', 'against', 'yourself', 'once', 'each', 'too', 'below', \"haven't\", 'don', 'has', 'hers', 'with', \"mightn't\", 've', 'do', 'which', 'under', 'from', 'or', 'while', 'wouldn', 'not', 'be', 'about', 'having', 'into', 'won', 'she', 'my', 'y', 'aren', 'by', 'had', 'mustn', \"that'll\", \"shouldn't\", \"you're\", 'was', 'ourselves', \"you'll\", 'me', 'of', 'haven', 'he', 'ours', 'both', 'on', 'shan', 'they', \"wouldn't\", \"isn't\", 'wasn', 'during', \"she's\", 'should', 'through', 'just', 'doing', 's', 'same', 'now', \"hasn't\", 'its', 'such', 'as', 'over', 'what', 'those', 'no', 'to', \"weren't\", \"mustn't\", 'nor'}\n"
     ]
    }
   ],
   "source": [
    "# What are those stopwords provided by NLTK?\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk_stop_words=set(stopwords.words(\"english\"))\n",
    "print(nltk_stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['Dogs', ',', 'Canis', 'lupus', 'familiaris', ',', 'are', 'domesticated', 'mammals', ',', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'a', 'long', 'time', ',', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', ',', 'some', 'dogs', 'are', 'used', 'as', 'pets', ',', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'a', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', ',', 'friendly', ',', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', ',', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', ',', 'including', 'as', 'police', 'dogs', ',', 'army', 'dogs', ',', 'assistance', 'dogs', ',', 'fire', 'dogs', ',', 'messenger', 'dogs', ',', 'hunting', 'dogs', ',', 'herding', 'dogs', ',', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', ',', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'is', 'called', 'a', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'is', 'called', 'a', 'puppy', 'until', 'it', 'is', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n",
      "\n",
      "\n",
      "Filterd Sentence: ['Dogs', 'Canis', 'lupus', 'familiaris', 'are', 'domesticated', 'mammals', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'long', 'time', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', 'some', 'dogs', 'are', 'used', 'as', 'pets', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', 'friendly', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', 'including', 'as', 'police', 'dogs', 'army', 'dogs', 'assistance', 'dogs', 'fire', 'dogs', 'messenger', 'dogs', 'hunting', 'dogs', 'herding', 'dogs', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'called', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'called', 'puppy', 'until', 'it', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n"
     ]
    }
   ],
   "source": [
    "filtered_words=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in my_stopwords:\n",
    "        filtered_words.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you apply the stopwords provided by NLTK (nltk stop words) to your text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentence: ['We', 'keep', 'this', 'love', 'in', 'a', 'photograph', '.', 'We', 'made', 'these', 'memories', 'for', 'ourselves', '.', 'Where', 'our', 'eyes', 'are', 'never', 'closing', '.', 'Hearts', 'are', 'never', 'broken', '.', 'And', 'time', \"'s\", 'forever', 'frozen', 'still']\n",
      "\n",
      "\n",
      "Filterd Sentence: ['We', 'keep', 'love', 'in', 'photograph', '.', 'We', 'made', 'these', 'memories', 'for', 'ourselves', '.', 'Where', 'our', 'eyes', 'are', 'never', 'closing', '.', 'Hearts', 'are', 'never', 'broken', '.', 'And', 'time', \"'s\", 'forever', 'frozen', 'still']\n"
     ]
    }
   ],
   "source": [
    "data = \"We keep this love in a photograph. We made these memories for ourselves. Where our eyes are never closing. Hearts are never broken. And time's forever frozen still\"\n",
    "stopWords = set(stopwords.words('english'))\n",
    "tokenized_word = word_tokenize(data)\n",
    "filtered_words2=[]\n",
    "for w in tokenized_word:\n",
    "    if w not in my_stopwords:\n",
    "        filtered_words2.append(w)\n",
    "print(\"Tokenized Sentence:\",tokenized_word)\n",
    "print(\"\\n\")\n",
    "print(\"Filterd Sentence:\",filtered_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "word = \"connection\"\n",
    "stem.stem(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' deriv'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "word = \" derivational\"\n",
    "stem.stem(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' multipli'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "word = \" multiplying\"\n",
    "stem.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Words: ['Dogs', 'Canis', 'lupus', 'familiaris', 'are', 'domesticated', 'mammals', 'not', 'natural', 'wild', 'animals', '.', 'They', 'were', 'originally', 'bred', 'from', 'wolves', '.', 'They', 'have', 'been', 'bred', 'by', 'humans', 'for', 'long', 'time', 'and', 'were', 'the', 'first', 'animals', 'ever', 'to', 'be', 'domesticated', '.', 'Today', 'some', 'dogs', 'are', 'used', 'as', 'pets', 'others', 'are', 'used', 'to', 'help', 'humans', 'do', 'their', 'work', '.', 'They', 'are', 'popular', 'pet', 'because', 'they', 'are', 'usually', 'playful', 'friendly', 'loyal', 'and', 'listen', 'to', 'humans', '.', 'Thirty', 'million', 'dogs', 'in', 'the', 'United', 'States', 'are', 'registered', 'as', 'pets', '.', 'Dogs', 'eat', 'both', 'meat', 'and', 'vegetables', 'often', 'mixed', 'together', 'and', 'sold', 'in', 'stores', 'as', 'dog', 'food', '.', 'Dogs', 'often', 'have', 'jobs', 'including', 'as', 'police', 'dogs', 'army', 'dogs', 'assistance', 'dogs', 'fire', 'dogs', 'messenger', 'dogs', 'hunting', 'dogs', 'herding', 'dogs', 'or', 'rescue', 'dogs', '.', 'They', 'are', 'sometimes', 'called', '``', 'canines', \"''\", 'from', 'the', 'Latin', 'word', 'for', 'dog', '-', 'canis', '.', 'Sometimes', 'people', 'also', 'use', '``', 'dog', \"''\", 'to', 'describe', 'other', 'canids', 'such', 'as', 'wolves', '.', 'A', 'baby', 'dog', 'called', 'pup', 'or', 'puppy', '.', 'A', 'dog', 'called', 'puppy', 'until', 'it', 'about', 'one', 'year', 'old', '.', 'Dogs', 'are', 'sometimes', 'referred', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'because', 'they', 'are', 'kept', 'as', 'domestic', 'pets', 'and', 'are', 'usually', 'loyal', 'and', 'like', 'being', 'around', 'humans', '.']\n",
      "\n",
      "\n",
      "Stemmed Words: ['dog', 'cani', 'lupu', 'familiari', 'are', 'domest', 'mammal', 'not', 'natur', 'wild', 'anim', '.', 'they', 'were', 'origin', 'bred', 'from', 'wolv', '.', 'they', 'have', 'been', 'bred', 'by', 'human', 'for', 'long', 'time', 'and', 'were', 'the', 'first', 'anim', 'ever', 'to', 'be', 'domest', '.', 'today', 'some', 'dog', 'are', 'use', 'as', 'pet', 'other', 'are', 'use', 'to', 'help', 'human', 'do', 'their', 'work', '.', 'they', 'are', 'popular', 'pet', 'becaus', 'they', 'are', 'usual', 'play', 'friendli', 'loyal', 'and', 'listen', 'to', 'human', '.', 'thirti', 'million', 'dog', 'in', 'the', 'unit', 'state', 'are', 'regist', 'as', 'pet', '.', 'dog', 'eat', 'both', 'meat', 'and', 'veget', 'often', 'mix', 'togeth', 'and', 'sold', 'in', 'store', 'as', 'dog', 'food', '.', 'dog', 'often', 'have', 'job', 'includ', 'as', 'polic', 'dog', 'armi', 'dog', 'assist', 'dog', 'fire', 'dog', 'messeng', 'dog', 'hunt', 'dog', 'herd', 'dog', 'or', 'rescu', 'dog', '.', 'they', 'are', 'sometim', 'call', '``', 'canin', \"''\", 'from', 'the', 'latin', 'word', 'for', 'dog', '-', 'cani', '.', 'sometim', 'peopl', 'also', 'use', '``', 'dog', \"''\", 'to', 'describ', 'other', 'canid', 'such', 'as', 'wolv', '.', 'A', 'babi', 'dog', 'call', 'pup', 'or', 'puppi', '.', 'A', 'dog', 'call', 'puppi', 'until', 'it', 'about', 'one', 'year', 'old', '.', 'dog', 'are', 'sometim', 'refer', 'to', 'as', '``', 'man', '’', 's', 'best', 'friend', \"''\", 'becaus', 'they', 'are', 'kept', 'as', 'domest', 'pet', 'and', 'are', 'usual', 'loyal', 'and', 'like', 'be', 'around', 'human', '.']\n"
     ]
    }
   ],
   "source": [
    "stem = PorterStemmer()\n",
    "stemmed_words=[]\n",
    "for w in filtered_words:\n",
    "    stemmed_words.append(stem.stem(w))\n",
    "print(\"Filtered Words:\",filtered_words)\n",
    "print(\"\\n\")\n",
    "print(\"Stemmed Words:\",stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'connect'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "word = \"connecting\"\n",
    "lem.lemmatize(word, pos=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly\n",
      "flying\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "word = \"flying\"\n",
    "print(lem.lemmatize(word, pos=\"v\"))\n",
    "print(lem.lemmatize(word, pos=\"n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "However, the two words differ in their flavor. Stemming usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes. Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v is verb\n",
    "# n is noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'studying', 'at', 'ICT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('studying', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('ICT', 'NNP')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"I am studying at ICT\"\n",
    "tokens=nltk.word_tokenize(sent)\n",
    "print(tokens)\n",
    "nltk.pos_tag(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('PRP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('VBG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('IN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping help\\tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}